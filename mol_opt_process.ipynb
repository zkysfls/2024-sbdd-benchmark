{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that process the output from mol_opt code\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def process_yaml_to_csv(yaml_file, csv_file):\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Input smiles', 'Docking score'])\n",
    "\n",
    "        for smiles, scores in data.items():\n",
    "            writer.writerow([smiles, scores[0] if scores else None])\n",
    "\n",
    "# Regex pattern to extract model and pdb_name\n",
    "pattern = re.compile(r'results_(.+)_(.+?)_docking_0\\.yaml$')\n",
    "# List of target directories\n",
    "target_directories = ['screening', 'graph_ga', 'smiles_ga',\n",
    "                      'smiles_vae', 'selfies_vae', 'moldqn',\n",
    "                      'reinvent', 'mimosa', 'smiles_lstm_hc',\n",
    "                      'dst', 'pasithea']  \n",
    "# Ensure the evaluation_output directory exists\n",
    "output_dir = '../evaluation_output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Traverse the directories\n",
    "for root, dirs, files in os.walk('main'):\n",
    "    # Check if the current directory is in the target list\n",
    "    if os.path.basename(root) in target_directories:\n",
    "        if 'results' in dirs:\n",
    "            results_dir = os.path.join(root, 'results')\n",
    "            # Process each YAML file in the results directory\n",
    "            for file in os.listdir(results_dir):\n",
    "                if file.endswith('.yaml'):\n",
    "                    match = pattern.match(file)\n",
    "                    if match:\n",
    "                        model, pdb_name = match.groups()\n",
    "                        # Skip files with model equal to 'qed'\n",
    "                        if pdb_name.lower() == 'qed':\n",
    "                            continue\n",
    "                        yaml_path = os.path.join(results_dir, file)\n",
    "                        csv_filename = f\"{pdb_name}_docking_{model}.csv\"\n",
    "                        csv_path = os.path.join(output_dir, csv_filename)\n",
    "                        process_yaml_to_csv(yaml_path, csv_path)\n",
    "                        print(f\"Processed {yaml_path} into {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated property CSV: ../eval_output_0304/3eml_property_3DSBDD.csv\n",
      "Generated property CSV: ../eval_output_0304/7l11_property_3DSBDD.csv\n",
      "Generated property CSV: ../eval_output_0304/3ny8_property_3DSBDD.csv\n",
      "Generated property CSV: ../eval_output_0304/4rlu_property_3DSBDD.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import csv\n",
    "import re\n",
    "from tdc import Oracle\n",
    "def generate_property_csv(sa_oracle, qed_oracle, logp_oracle, docking_csv_path, property_csv_path):\n",
    "    with open(docking_csv_path, 'r') as docking_file, open(property_csv_path, 'w', newline='') as property_file:\n",
    "        reader = csv.reader(docking_file)\n",
    "        writer = csv.writer(property_file)\n",
    "        writer.writerow(['Input smiles', 'SA', 'QED', 'LogP'])\n",
    "\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            smiles = row[0]\n",
    "            sa = sa_oracle(smiles)\n",
    "            qed = qed_oracle(smiles)\n",
    "            logp = logp_oracle(smiles)\n",
    "            writer.writerow([smiles, sa, qed, logp])\n",
    "\n",
    "sa_oracle = Oracle(name = 'SA')\n",
    "qed_oracle = Oracle(name = 'QED')\n",
    "logp_oracle = Oracle(name = 'LogP')\n",
    "# Directory containing the docking CSV files\n",
    "docking_dir = '../eval_output_0304'  # Replace with the actual directory if different\n",
    "\n",
    "# Regex pattern for identifying and parsing the docking CSV filenames\n",
    "pattern = re.compile(r'(.+)_docking_(.+)\\.csv$')\n",
    "\n",
    "# Process each docking CSV file in the directory\n",
    "for docking_csv_file in os.listdir(docking_dir):\n",
    "    match = pattern.match(docking_csv_file)\n",
    "    if match:\n",
    "        pdb_name, model = match.groups()\n",
    "        docking_csv_path = os.path.join(docking_dir, docking_csv_file)\n",
    "        property_csv_filename = f\"{pdb_name}_property_{model}.csv\"\n",
    "        property_csv_path = os.path.join(docking_dir, property_csv_filename)\n",
    "        generate_property_csv(sa_oracle, qed_oracle, logp_oracle, docking_csv_path, property_csv_path)\n",
    "        print(f\"Generated property CSV: {property_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdc_env",
   "language": "python",
   "name": "tdc_env"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
